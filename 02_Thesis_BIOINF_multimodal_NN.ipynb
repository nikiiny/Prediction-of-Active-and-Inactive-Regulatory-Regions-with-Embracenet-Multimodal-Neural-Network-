{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqpqu8UJFySp"
   },
   "source": [
    "## BIOINFORMATICS THESIS: MULTIMODAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EMCr7Kmoywoa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gensim\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import types\n",
    "\n",
    "#import optuna\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import re\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuhDdx1hy5QF",
    "outputId": "3c0936ff-f819-4c28-99db-d772ac7856c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.data_pipe import Load_Create_Task\n",
    "from BIOINF_tesi.data_pipe import Build_DataLoader_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d58d3a3f32432c97638119fcad2c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Loading data'), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = Load_Create_Task()\n",
    "data.load(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, labels_dict = data.get_task('active_E_vs_inactive_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation Done!\n",
      "\n",
      "Data Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "pipe_data_load = Build_DataLoader_Pipeline(data_dict, labels_dict, path_name='__.pickle', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=True,\n",
    "                    augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pos, w_neg = get_loss_weights_from_dataloader(train_loader)\n",
    "criterion=nn.CrossEntropyLoss(weight=torch.tensor([w_pos,w_neg]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A75bgOrvkxvH"
   },
   "source": [
    "## FUNCTIONS SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lPNL78PBy6HM"
   },
   "outputs": [],
   "source": [
    "# if the gpu is available the model is moved on the gpu memory\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.models.utils import load_model, save_best_model, plot_model_scores, get_loss_weights_from_dataloader"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('enhancers_prova_pipe_data_load.pickle', \"rb\") as fin:\n",
    "  pipe_data_load = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "x-uvmh_5zLZL"
   },
   "outputs": [],
   "source": [
    "#pip install pytorchtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lD5tUOn2zOnB"
   },
   "outputs": [],
   "source": [
    "# create a database to store optuna studies with sqlite backend\n",
    "\n",
    "engine = create_engine('sqlite:///SA_optuna_tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install botorch # quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgzeJth0nY0Y",
    "outputId": "e548228a-ec44-4135-acca-2abab2b752d2"
   },
   "outputs": [],
   "source": [
    "#!conda install botorch -c pytorch -c gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.data_pipe import Build_DataLoader_Pipeline\n",
    "\n",
    "data_dict, labels_dict = data.get_task('active_E_vs_active_P')\n",
    "\n",
    "pipe_data_load = Build_DataLoader_Pipeline(data_dict, labels_dict, path_name='n.pickle', \n",
    "                                           type_corr='kruskal_wallis_test', intersection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Trials():\n",
    "    \"\"\"Used for comparing different types of models and with and without augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.scores_dict = defaultdict(defaultdict(list))\n",
    "    \n",
    "    \n",
    "    def run(self,\n",
    "            build_dataloader_pipeline, \n",
    "            cell_line, \n",
    "            sequence=False, \n",
    "            model=None,\n",
    "            augmentation=False,\n",
    "            random_state=123,\n",
    "            k_trials=3, \n",
    "            criterion, \n",
    "            num_epochs=50, \n",
    "            input_size=None, \n",
    "            study_name=None,\n",
    "            hp_model_path=None, \n",
    "            test_model_path=None\n",
    "            ):\n",
    "        \n",
    "        self.k_trials = k_trials\n",
    "    \n",
    "    \n",
    "        for i in range(self.k_trials):\n",
    "            \n",
    "            print(f'TRIAL N. {i}')\n",
    "            print('\\n===============> HYPERPARAMETERS TUNING')\n",
    "\n",
    "            random_state = random_state + 100*i\n",
    "            train_loader, test_loader = pipe_data_load.return_data(cell_line=cell_line, hyper_tuning=True, \n",
    "                        sequence=sequence, random_state=random_state, augmentation=augmentation)\n",
    "\n",
    "            param_search = Param_Search(train_loader, test_loader,\n",
    "                                        criterion, num_epochs, input_size = input_size, \n",
    "                                        n_trials=5, study_name=study_name)\n",
    "\n",
    "            param_search.run_trial()\n",
    "            param_search.save_best_model(hp_model_path) #check the format\n",
    "\n",
    "            best_params = param_search.get_best_params()\n",
    "\n",
    "            lr = best_params['lr']\n",
    "            if best_params['optimizer'] == 'Adam':\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                \n",
    "            \n",
    "            train_loader, test_loader = pipe_data_load.return_data(cell_line=cell_line, hyper_tuning=False, \n",
    "                        sequence=sequence, random_state=random_state, augmentation=True)\n",
    "\n",
    "            print('\\n===============> MODEL TESTING')\n",
    "            \n",
    "            F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                            num_epochs, filename_path='__', patience=3, # check the format of filename_path\n",
    "                                    # NB: remove filename_path! not needed with new pc! or yes??\n",
    "                                    # \n",
    "                            sequence=sequence, verbose=False)\n",
    "            \n",
    "            self.scores_dict[f'trial_n_{i}'][f'F1_train'] = F1_train\n",
    "            self.scores_dict[f'trial_n_{i}'][f'F1_test'] = F1_test\n",
    "         #   save_best_model(model, test_model_path) #how to?\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \n",
    "        for i in self.k_trials:\n",
    "            print(f'TRAIL N. {i}')\n",
    "            plot_model_scores(self.scores_dict[f'trial_n_{i}'][f'F1_train'],\n",
    "                              self.scores_dict[f'trial_n_{i}'][f'F1_test'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2IoSXUq1afQ"
   },
   "source": [
    "# 1. FEED FORWARD NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LRJuJEnK1mit"
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "  \"\"\" Feed Forward neural network. It uses ReLU activation functions.\"\"\"\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(FFNN, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Linear(self.input_size, 100), \n",
    "        nn.ReLU())\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ReLU()) \n",
    "    \n",
    "\n",
    "    self.last_layer = nn.Linear(50, 2) \n",
    "    # mat1 and mat2 shapes cannot be multiplied (190x50 and 540x100)\n",
    "\n",
    "    self.drop_out1 = nn.Dropout(p=0.3)\n",
    "    self.drop_out2 = nn.Dropout(p=0.4) \n",
    "\n",
    "  def forward(self, x):\n",
    "      \n",
    "      \n",
    "    out = self.layer1(x)\n",
    "    out = self.drop_out1(out)\n",
    "\n",
    "    out = self.layer2(out)\n",
    "    out = self.drop_out2(out)\n",
    "    out = self.last_layer(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0iVxIZcMw_s"
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nItYRVDo10uR"
   },
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "J6reuM4o1gjW"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_-SFzs7q1A7E"
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='HEPG2', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZeskXVx61FF6"
   },
   "outputs": [],
   "source": [
    "def get_input_size_FFNN(data_loader):\n",
    "  for d,l in data_loader:\n",
    "    input_size = d.shape[1]\n",
    "    break\n",
    "  return input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OyoPA6SI3HTs"
   },
   "outputs": [],
   "source": [
    "input_size = get_input_size_FFNN(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "6AQS6rqr18O7"
   },
   "outputs": [],
   "source": [
    "get_loss_weights_from_dataloader(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "criterion=nn.CrossEntropyLoss(weight=torch.tensor([w_pos,w_neg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "d-gQioBg19K9",
    "outputId": "bf4f61d5-3cb7-42f7-b407-cdd39f61aac8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-85cc99011468>:158: ExperimentalWarning: BoTorchSampler is experimental (supported from v2.4.0). The interface can change in the future.\n",
      "  sampler=BoTorchSampler())\n",
      "\u001b[32m[I 2021-06-14 14:09:42,313]\u001b[0m A new study created in memory with name: hp_FFNN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f675cec21240d08b302d84fc29f058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e0556606904dd6ba1bed1ea66480e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babeac58b7e24f19909830c71e5a904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82eae5c81bf440e89ed9182394d081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8688920432d40fab826dcaf969d9efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-14 14:14:36,524]\u001b[0m Trial 0 finished with value: 0.20761762003837356 and parameters: {'n_layers': 3, 'n_units_l0': 369, 'dropout_l0': 0.4357738320752208, 'n_units_l1': 455, 'dropout_l1': 0.4073078141474769, 'n_units_l2': 347, 'dropout_l2': 0.4731143539113111, 'optimizer': 'RMSprop', 'lr': 0.04321534024331291}. Best is trial 0 with value: 0.20761762003837356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228fd234b32e4c24b777b447546fb9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e8fc93919949bc87717b5a82674b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dd7e0c7dc64e319ff02997f3958189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dad2c92484c4200a08cf6609fa59211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f18690e2d4ed4b3a964ba4b15f7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-14 14:18:30,514]\u001b[0m Trial 1 finished with value: 0.8307348694286952 and parameters: {'n_layers': 2, 'n_units_l0': 216, 'dropout_l0': 0.3155312391750696, 'n_units_l1': 459, 'dropout_l1': 0.28529844778180163, 'optimizer': 'RMSprop', 'lr': 2.7520615182966584e-05}. Best is trial 1 with value: 0.8307348694286952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  2\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  2\n",
      "Best trial:\n",
      "  Value:  0.8307348694286952\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 216\n",
      "    dropout_l0: 0.3155312391750696\n",
      "    n_units_l1: 459\n",
      "    dropout_l1: 0.28529844778180163\n",
      "    optimizer: RMSprop\n",
      "    lr: 2.7520615182966584e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Niki/opt/anaconda3/lib/python3.8/site-packages/optuna/structs.py:18: FutureWarning: `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "  warnings.warn(_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "param_search = Param_Search(train_loader, test_loader,\n",
    "            criterion, num_epochs, input_size = input_size,\n",
    "            n_trials=2, study_name='hp_FFNN')\n",
    "\n",
    "param_search.run_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPq8ax182E1R"
   },
   "outputs": [],
   "source": [
    "best_model_FFNN_hp = param_search.save_best_model('FFNN/best_model_FFNN_hp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpe-USry2QQv"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1M3XcKM10qMv"
   },
   "outputs": [],
   "source": [
    "#train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    " #                   hyper_tuning=True, \n",
    "  #                  sequence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TBnanKg92jG0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.models.utils import F1, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IqAKKNJu2kAp"
   },
   "outputs": [],
   "source": [
    "best_lr = 3.0174993222703274e-05 ##TRAIN\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a6d85f1038cd41da900f5edc0e80811d",
      "35b5608b0dc44af080ce58a099cd8712",
      "8fb7a0d167284bf79ff068a5aa85e9d2",
      "87899c5edd9342d2ac4b4ccc85ffc239",
      "61e41656f25e4a31b2fa8b673df87c31",
      "dc5de6784a954a5987ec7b2e85238215",
      "1726012577934d22976d0d887c1e9550",
      "1e7aad6fee9c4a78a819560cf7df65d1",
      "f1f8579b4d1b47b08269c9a8fbea17be",
      "f589903ecd1448d6a0eab7fce3b822f2",
      "6172d0db84ac405d90a81ca17e031d5e",
      "0bb7a6aef6f344068b1a1ef798debead",
      "52224afa7ed04cd59f64a33a124f15f8",
      "51871383359e47c5be7e7ed3763f8024",
      "0266ac46c9b9453a9539ea39e6710364",
      "b6812b69f4f840f0b2f733b077e83919",
      "1b704b6614534e2286d7203527c1c216",
      "a68fcc18c0f64e0f9bf6d3002bcab74d",
      "a5f107767969497fb1980cc0ab6262b0",
      "7b802877c3dc4c759de9a0bfc10ff400",
      "131a0ead97934369875db3b372dc2a2a",
      "316a7ea0a7af45a18856c3e17d3f8565",
      "8a4f2ba83b2a4291a5b332d025200abb",
      "2274bbb4d74148b2bf414c324b406965"
     ]
    },
    "id": "YvUj5GJs21OR",
    "outputId": "4edc335c-8663-47dc-a7d6-c135f3808212"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861b1c650ed488eb21bf7312a27da90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2942d4c2494c738a6fb0203b15ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training model'), FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-a0ca7c666da5>:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target)\n"
     ]
    }
   ],
   "source": [
    "F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                        num_epochs, filename_path='__', patience=3,\n",
    "                        sequence=True, verbose=True)\n",
    "\n",
    "#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')\n",
    "\n",
    "# REDUCE FILTERS SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q7ojMcD231j"
   },
   "outputs": [],
   "source": [
    "plot_model_scores(F1_train, F1_test, epochs=20,set_ylim=(0.82,0.88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TBnanKg92jG0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IqAKKNJu2kAp"
   },
   "outputs": [],
   "source": [
    "best_lr = 3.0174993222703274e-05 ##TRAIN\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.models.utils import F1, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a6d85f1038cd41da900f5edc0e80811d",
      "35b5608b0dc44af080ce58a099cd8712",
      "8fb7a0d167284bf79ff068a5aa85e9d2",
      "87899c5edd9342d2ac4b4ccc85ffc239",
      "61e41656f25e4a31b2fa8b673df87c31",
      "dc5de6784a954a5987ec7b2e85238215",
      "1726012577934d22976d0d887c1e9550",
      "1e7aad6fee9c4a78a819560cf7df65d1",
      "f1f8579b4d1b47b08269c9a8fbea17be",
      "f589903ecd1448d6a0eab7fce3b822f2",
      "6172d0db84ac405d90a81ca17e031d5e",
      "0bb7a6aef6f344068b1a1ef798debead",
      "52224afa7ed04cd59f64a33a124f15f8",
      "51871383359e47c5be7e7ed3763f8024",
      "0266ac46c9b9453a9539ea39e6710364",
      "b6812b69f4f840f0b2f733b077e83919",
      "1b704b6614534e2286d7203527c1c216",
      "a68fcc18c0f64e0f9bf6d3002bcab74d",
      "a5f107767969497fb1980cc0ab6262b0",
      "7b802877c3dc4c759de9a0bfc10ff400",
      "131a0ead97934369875db3b372dc2a2a",
      "316a7ea0a7af45a18856c3e17d3f8565",
      "8a4f2ba83b2a4291a5b332d025200abb",
      "2274bbb4d74148b2bf414c324b406965"
     ]
    },
    "id": "YvUj5GJs21OR",
    "outputId": "4edc335c-8663-47dc-a7d6-c135f3808212"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9839dbec1c2441d881a4d763b3ee8879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7984e9b2bd904a5c932f9fccc4002849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing model'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                        num_epochs, pre_trained=True, filename_path='FFNN/ffnn_testing', patience=3,\n",
    "                        sequence=True, verbose=True)\n",
    "\n",
    "#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')\n",
    "\n",
    "# REDUCE FILTERS SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu4BLdy81hvH"
   },
   "source": [
    "# 2. CONVOLUTIONAL NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB: must use 1d convolutional nn for sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.models import CNN_define_model, FFNN_define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeQBrIDh1qti"
   },
   "outputs": [],
   "source": [
    "def __init__(self, fc_layer_size, classes=2):\n",
    "    super(CNN_multitask, self).__init__()\n",
    "    self.fc_layer_size = fc_layer_size \n",
    "    self.classes = classes\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1), #The average word length in English language is 4.7 characters.\n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1))\n",
    "    \n",
    "    self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1)\n",
    "    \n",
    "        \n",
    "    self.drop_out1 = nn.Dropout(p=0.3)\n",
    "    self.drop_out2 = nn.Dropout(p=0.4)\n",
    "    self.drop_out3 = nn.Dropout(p=0.5)\n",
    "    \n",
    "    self.last_layer1 = nn.Linear(self.fc_layer_size, 1000) \n",
    "    self.last_layer2 = nn.Linear(1000, self.classes)\n",
    "    \n",
    "\n",
    "  def forward(self, x):\n",
    "      \n",
    "      # 2 shared blocks \n",
    "    out = self.layer1(x)\n",
    "    out = self.drop_out1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.drop_out2(out)\n",
    "    out = self.layer3(out) \n",
    "    out = self.drop_out3(out)\n",
    "    \n",
    "    out = out.reshape(out.size(0), -1) # batch, rest\n",
    "    out = self.last_layer1(out)\n",
    "    out = self.last_layer2(out)\n",
    "\n",
    " \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=torch.rand([100,256,4])\n",
    "out = out.reshape(out.size(0),out.size(1) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(o.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5383, 0.0530, 0.2218,  ..., 0.5969, 0.7685, 0.9807],\n",
       "        [0.4448, 0.5935, 0.5454,  ..., 0.2139, 0.2322, 0.3407],\n",
       "        [0.6433, 0.7899, 0.4144,  ..., 0.6058, 0.4562, 0.6550],\n",
       "        ...,\n",
       "        [0.1098, 0.7348, 0.9494,  ..., 0.2709, 0.9399, 0.1409],\n",
       "        [0.8204, 0.3057, 0.4057,  ..., 0.7834, 0.7073, 0.8876],\n",
       "        [0.4486, 0.5272, 0.8601,  ..., 0.8017, 0.5678, 0.8476]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.reshape(o.size(0), -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab087b78ebd4bfb9c369b66127b772c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c6cb92d0414c1b9e44cd7720f3739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[192, 1, 257, 5] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0ffd8b036a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_trained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FFNN/ffnn_testing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         sequence=True, verbose=True)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-202667f61e6c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, pre_trained, filename_path, patience, sequence, delta, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;31m# calculate the batch loss as the sum of all the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[192, 1, 257, 5] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                        num_epochs, pre_trained=True, filename_path='FFNN/ffnn_testing', patience=3,\n",
    "                        sequence=True, verbose=True)\n",
    "\n",
    "#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_Thesis_BIOINF_multimodal_NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0266ac46c9b9453a9539ea39e6710364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bb7a6aef6f344068b1a1ef798debead": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6812b69f4f840f0b2f733b077e83919",
      "placeholder": "​",
      "style": "IPY_MODEL_0266ac46c9b9453a9539ea39e6710364",
      "value": " 405/? [01:19&lt;00:00,  5.12it/s]"
     }
    },
    "131a0ead97934369875db3b372dc2a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1726012577934d22976d0d887c1e9550": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b704b6614534e2286d7203527c1c216": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5f107767969497fb1980cc0ab6262b0",
       "IPY_MODEL_7b802877c3dc4c759de9a0bfc10ff400"
      ],
      "layout": "IPY_MODEL_a68fcc18c0f64e0f9bf6d3002bcab74d"
     }
    },
    "1e7aad6fee9c4a78a819560cf7df65d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2274bbb4d74148b2bf414c324b406965": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a7ea0a7af45a18856c3e17d3f8565": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b5608b0dc44af080ce58a099cd8712": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51871383359e47c5be7e7ed3763f8024": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52224afa7ed04cd59f64a33a124f15f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6172d0db84ac405d90a81ca17e031d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Training model: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51871383359e47c5be7e7ed3763f8024",
      "max": 404,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52224afa7ed04cd59f64a33a124f15f8",
      "value": 404
     }
    },
    "61e41656f25e4a31b2fa8b673df87c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b802877c3dc4c759de9a0bfc10ff400": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2274bbb4d74148b2bf414c324b406965",
      "placeholder": "​",
      "style": "IPY_MODEL_8a4f2ba83b2a4291a5b332d025200abb",
      "value": " 37/? [14:25&lt;00:00, 23.40s/it]"
     }
    },
    "87899c5edd9342d2ac4b4ccc85ffc239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e7aad6fee9c4a78a819560cf7df65d1",
      "placeholder": "​",
      "style": "IPY_MODEL_1726012577934d22976d0d887c1e9550",
      "value": " 0/2 [01:32&lt;?, ?it/s]"
     }
    },
    "8a4f2ba83b2a4291a5b332d025200abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fb7a0d167284bf79ff068a5aa85e9d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Epochs:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc5de6784a954a5987ec7b2e85238215",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61e41656f25e4a31b2fa8b673df87c31",
      "value": 0
     }
    },
    "a5f107767969497fb1980cc0ab6262b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Testing model: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_316a7ea0a7af45a18856c3e17d3f8565",
      "max": 36,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_131a0ead97934369875db3b372dc2a2a",
      "value": 36
     }
    },
    "a68fcc18c0f64e0f9bf6d3002bcab74d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d85f1038cd41da900f5edc0e80811d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fb7a0d167284bf79ff068a5aa85e9d2",
       "IPY_MODEL_87899c5edd9342d2ac4b4ccc85ffc239"
      ],
      "layout": "IPY_MODEL_35b5608b0dc44af080ce58a099cd8712"
     }
    },
    "b6812b69f4f840f0b2f733b077e83919": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc5de6784a954a5987ec7b2e85238215": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f8579b4d1b47b08269c9a8fbea17be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6172d0db84ac405d90a81ca17e031d5e",
       "IPY_MODEL_0bb7a6aef6f344068b1a1ef798debead"
      ],
      "layout": "IPY_MODEL_f589903ecd1448d6a0eab7fce3b822f2"
     }
    },
    "f589903ecd1448d6a0eab7fce3b822f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
