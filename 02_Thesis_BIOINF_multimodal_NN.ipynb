{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqpqu8UJFySp"
   },
   "source": [
    "## BIOINFORMATICS THESIS: MULTIMODAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EMCr7Kmoywoa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Niki/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gensim\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import types\n",
    "\n",
    "#import optuna\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import re\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy.stats import spearmanr\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuhDdx1hy5QF",
    "outputId": "3c0936ff-f819-4c28-99db-d772ac7856c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: cliff in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (3.7.0)\n",
      "Requirement already satisfied: numpy in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (1.19.2)\n",
      "Requirement already satisfied: colorlog in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (5.0.1)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: tqdm in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (4.50.2)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (1.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (20.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (1.3.20)\n",
      "Requirement already satisfied: alembic in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from optuna) (1.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (2.4.7)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (1.5.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (2.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (5.3.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cliff->optuna) (5.6.0)\n",
      "Requirement already satisfied: six in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
      "Requirement already satisfied: Mako in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from alembic->optuna) (1.1.4)\n",
      "Requirement already satisfied: python-dateutil in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BIOINF_tesi.data_pipe import Load_Create_Task\n",
    "from BIOINF_tesi.data_pipe import Build_DataLoader_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46a825550e04ac2bae7bfbbb73d1ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Loading data'), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b628f3afbb2d48f1b34917d77b98a949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Loading data'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "enhancers files:\n",
      "['A549', 'GM12878', 'H1', 'HEK293', 'HEPG2', 'K562', 'MCF7', 'bed', 'fa']\n",
      "\n",
      "bed has shape: (63285, 11)\n",
      "MCF7 has shape: (63285, 121)\n",
      "GM12878 has shape: (63285, 156)\n",
      "A549 has shape: (63285, 52)\n",
      "H1 has shape: (63285, 62)\n",
      "K562 has shape: (63285, 433)\n",
      "fa has shape: (63285, 4)\n",
      "HEPG2 has shape: (63285, 566)\n",
      "HEK293 has shape: (63285, 200)\n",
      "\n",
      "promoters files:\n",
      "['A549', 'GM12878', 'H1', 'HEK293', 'HEPG2', 'K562', 'MCF7', 'bed', 'fa']\n",
      "\n",
      "MCF7 has shape: (99881, 121)\n",
      "fa has shape: (99881, 4)\n",
      "GM12878 has shape: (99881, 156)\n",
      "A549 has shape: (99881, 52)\n",
      "H1 has shape: (99881, 62)\n",
      "K562 has shape: (99881, 433)\n",
      "HEPG2 has shape: (99881, 566)\n",
      "bed has shape: (99881, 11)\n",
      "HEK293 has shape: (99881, 200)\n"
     ]
    }
   ],
   "source": [
    "data = Load_Create_Task()\n",
    "data.load(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, labels_dict = data.get_task('inactive_E_vs_inactive_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "pipe_data_load = Build_DataLoader_Pipeline(data_dict, labels_dict, path_name='.pickle', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A75bgOrvkxvH"
   },
   "source": [
    "## FUNCTIONS SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('enhancers_prova_pipe_data_load.pickle', \"rb\") as fin:\n",
    "  pipe_data_load = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lPNL78PBy6HM"
   },
   "outputs": [],
   "source": [
    "# if the gpu is available the model is moved on the gpu memory\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jJ0zoqiyzD3s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def F1(output, target):\n",
    "  pred = torch.argmax(output, dim=1)\n",
    "  return f1_score(pred.cpu().detach().numpy(), target.cpu().detach().numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "x-uvmh_5zLZL"
   },
   "outputs": [],
   "source": [
    "#pip install pytorchtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lD5tUOn2zOnB"
   },
   "outputs": [],
   "source": [
    "# create a database to store optuna studies with sqlite backend\n",
    "\n",
    "engine = create_engine('sqlite:///SA_optuna_tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting botorch\n",
      "  Downloading botorch-0.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[K     |████████████████████████████████| 395 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from botorch) (1.8.1)\n",
      "Requirement already satisfied: scipy in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from botorch) (1.5.2)\n",
      "Collecting gpytorch>=1.4\n",
      "  Downloading gpytorch-1.4.2-py2.py3-none-any.whl (492 kB)\n",
      "\u001b[K     |████████████████████████████████| 492 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.7.1->botorch) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.7.1->botorch) (3.7.4.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from gpytorch>=1.4->botorch) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->gpytorch>=1.4->botorch) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->gpytorch>=1.4->botorch) (0.17.0)\n",
      "Installing collected packages: gpytorch, botorch\n",
      "Successfully installed botorch-0.4.0 gpytorch-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgzeJth0nY0Y",
    "outputId": "e548228a-ec44-4135-acca-2abab2b752d2"
   },
   "outputs": [],
   "source": [
    "#!conda install botorch -c pytorch -c gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NgNw-_5kzRoh"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import botorch\n",
    "from optuna.integration import BoTorchSampler\n",
    "\n",
    "class Param_Search():\n",
    "\n",
    "  def __init__(self, \n",
    "               #network_type,\n",
    "               train_loader, \n",
    "               test_loader,\n",
    "               criterion,\n",
    "               num_epochs,\n",
    "               study_name,\n",
    "               input_size,\n",
    "               sequence=False, \n",
    "               n_trials=4\n",
    "               ):\n",
    "    # self.network_type = network_type\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.criterion = criterion\n",
    "    self.num_epochs = num_epochs\n",
    "    self.study_name = study_name\n",
    "    self.input_size = input_size\n",
    "    self.sequence = sequence\n",
    "    self.n_trials = n_trials\n",
    "    self.best_model = None\n",
    "\n",
    "    self.oversample_SMOTE = SMOTE(k_neighbors=3)\n",
    "    self.oversample_SMOTEN = SMOTEN(k_neighbors=3)\n",
    "    self.onehot_encoder = OneHotEncoder(sparse=False).fit(np.array([0,1,2,4]).reshape(-1, 1)) \n",
    "    \n",
    "    \"\"\"Performs the hyper parameters tuning by using a TPE (Tree-structured Parzen Estimator) \n",
    "    algorithm sampler.  \n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): neural network model.\n",
    "    train_loader (DataLoader): training DataLoader object.\n",
    "    test_loader (DataLoader): testing DataLoader object.\n",
    "    criterion : loss function for training the model.\n",
    "    num_epochs (int): number of epochs.\n",
    "    study_name (str): name of the Optuna study object.\n",
    "    n_trial (int): number of trials to perform in the Optuna study.\n",
    "        Default: 4\n",
    "    \n",
    "    Attributes:\n",
    "    ------------------\n",
    "    best_model: stores the weights of the common layers of the best performing model.\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "    Prints values of the optimised hyperparameters and saves the parameters of the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "  def objective(self, trial):\n",
    "    \"\"\"Defines the objective to be optimised (F1 test score) and saves\n",
    "    each final model.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate the model\n",
    "    model = FFNN_define_model(trial, in_features_INPUT=self.input_size, classes=2)\n",
    "\n",
    "    # generate the possible optimizers\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # convert model data type to double\n",
    "    model = model.double()\n",
    "\n",
    "    \n",
    "    # Define the training and testing phases\n",
    "    for epoch in tqdm(range(1, self.num_epochs + 1), desc='Epochs'):\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        f1_test = 0.0\n",
    "\n",
    "        # set the model in training modality\n",
    "        model.train()\n",
    "        for data, target in tqdm(self.train_loader, desc='Training Model'):\n",
    "            \n",
    "            if self.sequence:\n",
    "            #n_batches, n.elements per obs\n",
    "                data = data.reshape(data.shape[0], -1)\n",
    "                data,target = self.oversample_SMOTEN.fit_resample(data,target)\n",
    "                # one-hot encode (must do it after oversampling)\n",
    "                data_encoded = []\n",
    "                for x in data:\n",
    "                    data_encoded.append(self.onehot_encoder.transform(np.array(x).reshape(-1, 1)))\n",
    "                # final size: n_batches, n_channels, size of matrix (256*4)\n",
    "                data = torch.tensor(data_encoded).reshape(-1,1,256,4)\n",
    "\n",
    "            else:\n",
    "                data, target = self.oversample_SMOTE.fit_resample(data, target.ravel())\n",
    "                data = torch.tensor(data)\n",
    "        \n",
    "            target = torch.tensor(target)\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.double())\n",
    "            # calculate the batch loss as a sum of the single losses\n",
    "            loss = self.criterion(output, target) \n",
    "            # backward pass: compute gradient of the loss wrt model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # set the model in testing modality\n",
    "        model.eval()\n",
    "        for data, target in tqdm(self.test_loader, desc='Testing Model'):  \n",
    "\n",
    "            if self.sequence:\n",
    "                # one-hot encode (must do it after oversampling)\n",
    "                data_encoded = []\n",
    "                for x in data:\n",
    "                    data_encoded.append(self.onehot_encoder.transform(x))\n",
    "                # final size: n_batches, n_channels, size of matrix (256*4)\n",
    "                data = torch.tensor(data_encoded).reshape(-1,1,256,4)\n",
    "        \n",
    "            target=target.reshape(-1) #########\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.double())\n",
    "            # calculate the batch loss as a sum of the single losses\n",
    "            loss = self.criterion(output, target)\n",
    "            # update test loss \n",
    "            test_loss += loss.item()\n",
    "            # calculate F1 test score as weighted sum of the single F1 scores\n",
    "            f1_test += F1(output,target)\n",
    "\n",
    "          # calculate epoch score by dividing by the number of observations\n",
    "        f1_test /= (len(self.test_loader))\n",
    "    \n",
    "        # pass the score of the epoch to the study to monitor the intermediate objective values\n",
    "        trial.report(f1_test, epoch)\n",
    "\n",
    "    # save the final model named with the number of the trial \n",
    "    with open(\"{}{}.pickle\".format(self.study_name, trial.number), \"wb\") as fout:\n",
    "        pickle.dump(model, fout)\n",
    "    \n",
    "    # return F1 score to the study\n",
    "    return f1_test\n",
    "\n",
    "\n",
    "\n",
    "  def run_trial(self):\n",
    "    \"\"\"Runs Optuna study and stores the best model in class attribute 'best_model'.\"\"\"\n",
    "    \n",
    "    # create a new study or load a pre-existing study. use sqlite backend to store the study.\n",
    "    study = optuna.create_study(study_name=self.study_name, direction=\"maximize\", \n",
    "                               # storage='sqlite:///SA_optuna_tuning.db', load_if_exists=True,\n",
    "                                sampler=BoTorchSampler())\n",
    "    \n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "    \n",
    "    # if the number of already completed trials is lower than the total number of trials passed as\n",
    "    #argument, perform the remaining trials \n",
    "    if len(complete_trials)<self.n_trials:\n",
    "        # set the number of trials to be performed equal to the number of missing trials\n",
    "        self.n_trials -= len(complete_trials)\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "        complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "        \n",
    "    # store the best model found in the class\n",
    "    with open(\"{}{}.pickle\".format(self.study_name, study.best_trial.number), \"rb\") as fin:\n",
    "        best_model = pickle.load(fin)\n",
    "\n",
    "    self.best_model = best_model\n",
    "\n",
    "    \n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    \n",
    "    \n",
    "  def save_best_model(self, path):\n",
    "    \"\"\"Saves the weights of the common layers of the best performing model.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    path: path where the model will be stored.\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "    Weights of the common layers of the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve the weights of the best model\n",
    "    model_param = self.best_model.state_dict()\n",
    "    \n",
    "    # save only the weights of the common layers\n",
    "    for key,value in model_param.copy().items():\n",
    "        if re.findall('last', key):\n",
    "            del model_param[str(key)]\n",
    "\n",
    "    gdrive_path = '/content/gdrive/MyDrive/Thesis_BIOINF' ###\n",
    "    basepath = 'models' \n",
    "    basepath = grive_path + basepath ###\n",
    "    path = os.path.join(basepath, path)\n",
    "\n",
    "    torch.save(model_param, path)\n",
    "\n",
    "    return model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "smPmNwJAzqrV"
   },
   "outputs": [],
   "source": [
    "# modified from https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "        patience (int): How long to wait after last time validation loss improved.\n",
    "            Default: 7\n",
    "        verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "            Default: False\n",
    "        delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            Default: 0\n",
    "        trace_func (function): trace print function.\n",
    "            Default: print \n",
    "                            \n",
    "    Attributes:\n",
    "    ------------------\n",
    "        early_stop (bool): True if the validation loss doesn't improveand the training should\n",
    "            be stopped, False else.\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, patience=3, verbose=False, delta=0, trace_func=print):\n",
    "       \n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        # if the new score is worse than the previous score, add 1 to the counter\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            # if the number of non-improving epochs is greater than patience, \n",
    "            #set to True early_stop attribute \n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vPB5r6BSw49P"
   },
   "outputs": [],
   "source": [
    "import imblearn.over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "U69oq6Ikw0tX",
    "outputId": "b2f727c6-210f-44d8-f7e6-d0115b781e34"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "bJ2tyb5TzsSm"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.over_sampling import SMOTEN\n",
    "    \n",
    "\n",
    "def fit(model, \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        criterion, \n",
    "        optimizer=None, \n",
    "        num_epochs=50, \n",
    "        pre_trained = False,\n",
    "        filename_path=None, \n",
    "        patience=3,\n",
    "        sequence=False,\n",
    "        delta=0,\n",
    "        verbose=True): \n",
    "    \n",
    "  \"\"\"Performs the training of the multitask model. It implements also early stopping\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): neural network model.\n",
    "    train_loader (DataLoader): training DataLoader object.\n",
    "    test_loader (DataLoader): testing DataLoader object.\n",
    "    criterion: loss function for training the model.\n",
    "    optimizer (torch.optim): optimization algorithm for training the model. \n",
    "    num_epochs (int): number of epochs.\n",
    "    filename_path (str): where the weights of the model at each epoch will be stored. \n",
    "        Indicate only the name of the folder.\n",
    "    patience (int): number of epochs in which the test error is not anymore decreasing\n",
    "        before stopping the training.\n",
    "    delta (int): minimum decrease in the test error to continue with the training.\n",
    "        Default:0\n",
    "    verbose (bool): prints the training error, test error, F1 training score, F1 test score \n",
    "        at each epoch.\n",
    "        Default: True\n",
    "    \n",
    "    Attributes:\n",
    "    ------------------\n",
    "    f1_train_scores: stores the F1 training scores for each epoch.\n",
    "    f1_test_scores: stores the F1 test scores for each epoch.\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "    Lists of F1 training scores and F1 test scores at each epoch.\n",
    "    Prints training error, test error, F1 training score, F1 test score at each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "  gdrive_path = '/content/gdrive/MyDrive/Thesis_BIOINF' ###\n",
    "  basepath = 'exp'\n",
    "  basepath = gdrive_path + basepath ###\n",
    "\n",
    "  oversample_SMOTE = SMOTE(k_neighbors=3)\n",
    "  #oversample_SMOTEN = imblearn.over_sampling.SMOTEN(k_neighbors=3)\n",
    "  onehot_encoder = OneHotEncoder(sparse=False).fit(np.array([0,1,2,4]).reshape(-1, 1)) \n",
    "\n",
    "\n",
    "  # keep track of epoch losses \n",
    "  f1_train_scores = []\n",
    "  f1_test_scores = []\n",
    "\n",
    "  # convert model data type to double\n",
    "  model = model.double()\n",
    "\n",
    "  # define early stopping\n",
    "  early_stopping = EarlyStopping(patience=patience, delta=delta, verbose=True)\n",
    "    \n",
    "    \n",
    "  for epoch in tqdm(range(1, num_epochs + 1), desc='Epochs'):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    f1_train = 0.0\n",
    "    f1_test = 0.0\n",
    "    \n",
    "    if pre_trained:\n",
    "        pass\n",
    "    \n",
    "    # if there is already a trained model stored for a specific epoch, load the model\n",
    "    #and don't retrain the model\n",
    "    elif os.path.exists( os.path.join(basepath, filename_path + '_' + str(epoch) + '.pt') ):\n",
    "      checkpoint = torch.load(PATH)\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      f1_train = checkpoint['F1_train']\n",
    "      f1_test = checkpoint['F1_test']\n",
    "      train_loss = checkpoint['train_loss']\n",
    "      test_loss = checkpoint['test_loss']\n",
    "    \n",
    "    else:\n",
    "\n",
    "      # set the model in training modality\n",
    "      model.train()\n",
    "\n",
    "      for data, target in tqdm(train_loader, desc='Training model'):\n",
    "        \n",
    "        # oversample using SMOTE / SMOTEN\n",
    "        if sequence:\n",
    "          #n_batches, n.elements per obs\n",
    "          data = data.reshape(data.shape[0], -1)\n",
    "          #data,target = oversample_SMOTEN.fit_resample(data,target)\n",
    "          # one-hot encode (must do it after oversampling)\n",
    "          data_encoded = []\n",
    "          for x in data:\n",
    "            data_encoded.append(onehot_encoder.transform(np.array(x).reshape(-1, 1)))\n",
    "          # final size: n_batches, n_channels, size of matrix (256*4)\n",
    "          data = torch.tensor(data_encoded).reshape(-1,1,256,4)\n",
    "\n",
    "        else:\n",
    "          data, target = oversample_SMOTE.fit_resample(data, target.ravel())\n",
    "          data = torch.tensor(data)\n",
    "        \n",
    "        target = torch.tensor(target)\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.double())\n",
    "        # calculate the batch loss as the sum of all the losses\n",
    "        loss = criterion(output, target) \n",
    "        # backward pass: compute gradient of the loss wrt model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()\n",
    "        # calculate F1 training score as a weighted sum of the single F1 scores\n",
    "        f1_train += F1(output,target)\n",
    "\n",
    "        \n",
    "      # set the model in testing modality\n",
    "    model.eval()\n",
    "    for data, target in tqdm(test_loader, desc='Testing model'):\n",
    "\n",
    "        if sequence:\n",
    "          # one-hot encode (must do it after oversampling)\n",
    "          data_encoded = []\n",
    "          for x in data:\n",
    "            data_encoded.append(onehot_encoder.transform(x))\n",
    "          # final size: n_batches, n_channels, size of matrix (256*4)\n",
    "          data = torch.tensor(data_encoded).reshape(-1,1,256,4)\n",
    "        \n",
    "        target=target.reshape(-1)\n",
    "\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.double())\n",
    "        # calculate the batch loss as the sum of all the losses\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss\n",
    "        test_loss += loss.item()\n",
    "        # calculate F1 test score as a weighted sum of the single F1 scores\n",
    "        f1_test += F1(output,target) \n",
    "    \n",
    "    \n",
    "    if pre_trained:\n",
    "        continue\n",
    "    else:\n",
    "        # save the model weights, epoch, scores and losses at each epoch\n",
    "        model_param = model.state_dict()\n",
    "        PATH = os.path.join(basepath, filename_path + '_' + str(epoch) + '.pt')\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model_param,\n",
    "                    'F1_train': f1_train,\n",
    "                    'F1_test': f1_test,\n",
    "                    'train_loss': train_loss,\n",
    "                    'test_loss': test_loss},\n",
    "                   PATH)\n",
    "    \n",
    "    if pre_trained:\n",
    "        pass\n",
    "        # calculate epoch score by dividing by the number of observations\n",
    "        f1_train /= (len(train_loader))\n",
    "        f1_test /= (len(test_loader))\n",
    "    # store epoch score\n",
    "    f1_train_scores.append(f1_train)    \n",
    "    f1_test_scores.append(f1_test)\n",
    "      \n",
    "    # print training/test statistics \n",
    "    if verbose == True:\n",
    "      print('Epoch: {} \\tTraining F1 score: {:.4f} \\tTest F1 score: {:.4f} \\tTraining Loss: {:.4f} \\tTest Loss: {:.4f}'.format(\n",
    "      epoch, f1_train, f1_test, train_loss, test_loss))\n",
    "    \n",
    "    \n",
    "    if pre_trained:\n",
    "        pass\n",
    "    else:\n",
    "        # early stop the model if the test loss is not improving\n",
    "        early_stopping(test_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "          print('Early stopping the training')\n",
    "          # reload the previous best model before the test loss started decreasing\n",
    "          best_checkpoint = torch.load(os.path.join(basepath,filename_path + '_' + '{}'.format(epoch-patience) + '.pt'))\n",
    "          model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "          break\n",
    "\n",
    "  \n",
    "  # return the scores at each epoch\n",
    "  return f1_train_scores, f1_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vaWtLyIs0D40"
   },
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "  \"\"\"Load the stored weights of a pre-trained model into another\n",
    "      model and set it to eval state.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): not trained neural network model.\n",
    "    path (str): path of the stored weights of the pre-trained model. \n",
    "    \"\"\"\n",
    "\n",
    "  gdrive_path = '/content/gdrive/MyDrive/Thesis_BIOINF' ###\n",
    "  basepath = 'models'\n",
    "  basepath = gdrive_path + basepath ###\n",
    "\n",
    "  path = os.path.join(basepath, path)\n",
    "  checkpoint = torch.load(path)\n",
    "  model.load_state_dict(checkpoint) \n",
    "  # set the model in testing modality\n",
    "  model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ACCJJ5xX0E4a"
   },
   "outputs": [],
   "source": [
    "def save_best_model(model, path):\n",
    "    \"\"\"Saves only the weights of the common layers of a\n",
    "    trained neural network. \n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): trained neural network model.\n",
    "    path (str): path where the weights of the trained model will be stored. \n",
    "    \"\"\"\n",
    "    \n",
    "    model_param = model.state_dict()\n",
    "    for key,value in model_param.copy().items():\n",
    "      if re.findall('last', key):\n",
    "        del model_param[str(key)]\n",
    "\n",
    "    gdrive_path = '/content/gdrive/MyDrive/Thesis_BIOINF' ###\n",
    "    basepath = 'models'\n",
    "    basepath = gdrive_path + basepath ###\n",
    "    PATH = os.path.join(basepath, path)\n",
    "    \n",
    "    torch.save(model_param, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yvhsw4Us0J_2"
   },
   "outputs": [],
   "source": [
    "def plot_model_scores(y_train, y_test, epochs, set_ylim=None):\n",
    "    \"\"\"Plots the trend of the training and test loss function of \n",
    "        a model.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    y_train (list): list of training losses.\n",
    "    y_test (list): list of test losses.\n",
    "    epochs (int): number of epochs.\n",
    "    set_ylim (tuple of int): range of y-axis.\n",
    "        Default: None\n",
    "    \"\"\"\n",
    "   \n",
    "    epochs = range(epochs)\n",
    "    X=pd.DataFrame({'epochs':epochs,'y_train':y_train,'y_test':y_test})\n",
    "   \n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    sns.set(rc={'figure.figsize':(30,15)})\n",
    "\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "\n",
    "    sns.lineplot(data=X, x=\"epochs\", y=\"y_test\", color='red',lw=2.5)\n",
    "    sns.lineplot(data=X, x=\"epochs\", y=\"y_train\", color='green',lw=2.5)\n",
    "\n",
    "    plt.legend(labels=['F1 test score', 'F1 train score'])\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=35)\n",
    "    plt.setp(ax.get_legend().get_title(),fontsize=35)\n",
    "\n",
    "    ax.set_ylabel('F1 score', fontsize=30)\n",
    "    ax.set_xlabel('Epochs', fontsize=30)\n",
    "    ax.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax.set_ylim(set_ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PDshoQQHHQ2t"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "  pred = torch.argmax(y_hat, dim=1)\n",
    "  # return the category with the highest probability\n",
    "  return (pred == y).float().mean()\n",
    "  # return true if the predicted category is equal to the true one, false otherwise.\n",
    "  #we transform them in float, 1 if True, 0 is False, then we return the mean of the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2IoSXUq1afQ"
   },
   "source": [
    "# 1. FEED FORWARD NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "QgZRa7ixiqkh"
   },
   "outputs": [],
   "source": [
    "class FFNN_define_model(nn.Module):\n",
    "\n",
    "    def __init__(self, trial, in_features_INPUT, classes=2):\n",
    "        super(FFNN_define_model, self).__init__()\n",
    "        self.trial = trial\n",
    "        self.in_features_INPUT = in_features_INPUT\n",
    "        self.classes = classes\n",
    "        self.model = []\n",
    "        \n",
    "        # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "        n_layers = self.trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        layers = []\n",
    "\n",
    "        in_features = self.in_features_INPUT\n",
    "        for i in range(n_layers):\n",
    "            out_features = self.trial.suggest_int(\"n_units_l{}\".format(i), 4, self.in_features_INPUT)\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            p = self.trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "            layers.append(nn.Dropout(p))\n",
    "\n",
    "            in_features = out_features\n",
    "\n",
    "        layers.append(nn.Linear(in_features, self.classes))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LRJuJEnK1mit"
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "  \"\"\" Feed Forward neural network. It uses ReLU activation functions.\"\"\"\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(FFNN, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Linear(self.input_size, 100), \n",
    "        nn.ReLU())\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ReLU()) \n",
    "    \n",
    "\n",
    "    self.last_layer = nn.Linear(50, 2) \n",
    "    # mat1 and mat2 shapes cannot be multiplied (190x50 and 540x100)\n",
    "\n",
    "    self.drop_out1 = nn.Dropout(p=0.3)\n",
    "    self.drop_out2 = nn.Dropout(p=0.4) \n",
    "\n",
    "  def forward(self, x):\n",
    "      \n",
    "      \n",
    "    out = self.layer1(x)\n",
    "    out = self.drop_out1(out)\n",
    "\n",
    "    out = self.layer2(out)\n",
    "    out = self.drop_out2(out)\n",
    "    out = self.last_layer(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0iVxIZcMw_s"
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nItYRVDo10uR"
   },
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J6reuM4o1gjW"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "_-SFzs7q1A7E"
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='HEPG2', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZeskXVx61FF6"
   },
   "outputs": [],
   "source": [
    "def get_input_size_FFNN(data_loader):\n",
    "  for d,l in data_loader:\n",
    "    input_size = d.shape[1]\n",
    "    break\n",
    "  return input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OyoPA6SI3HTs"
   },
   "outputs": [],
   "source": [
    "input_size = get_input_size_FFNN(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "6AQS6rqr18O7"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "d-gQioBg19K9",
    "outputId": "bf4f61d5-3cb7-42f7-b407-cdd39f61aac8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-85cc99011468>:158: ExperimentalWarning: BoTorchSampler is experimental (supported from v2.4.0). The interface can change in the future.\n",
      "  sampler=BoTorchSampler())\n",
      "\u001b[32m[I 2021-06-14 14:09:42,313]\u001b[0m A new study created in memory with name: hp_FFNN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f675cec21240d08b302d84fc29f058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e0556606904dd6ba1bed1ea66480e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babeac58b7e24f19909830c71e5a904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82eae5c81bf440e89ed9182394d081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8688920432d40fab826dcaf969d9efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-14 14:14:36,524]\u001b[0m Trial 0 finished with value: 0.20761762003837356 and parameters: {'n_layers': 3, 'n_units_l0': 369, 'dropout_l0': 0.4357738320752208, 'n_units_l1': 455, 'dropout_l1': 0.4073078141474769, 'n_units_l2': 347, 'dropout_l2': 0.4731143539113111, 'optimizer': 'RMSprop', 'lr': 0.04321534024331291}. Best is trial 0 with value: 0.20761762003837356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228fd234b32e4c24b777b447546fb9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e8fc93919949bc87717b5a82674b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dd7e0c7dc64e319ff02997f3958189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dad2c92484c4200a08cf6609fa59211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f18690e2d4ed4b3a964ba4b15f7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing Model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-14 14:18:30,514]\u001b[0m Trial 1 finished with value: 0.8307348694286952 and parameters: {'n_layers': 2, 'n_units_l0': 216, 'dropout_l0': 0.3155312391750696, 'n_units_l1': 459, 'dropout_l1': 0.28529844778180163, 'optimizer': 'RMSprop', 'lr': 2.7520615182966584e-05}. Best is trial 1 with value: 0.8307348694286952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  2\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  2\n",
      "Best trial:\n",
      "  Value:  0.8307348694286952\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 216\n",
      "    dropout_l0: 0.3155312391750696\n",
      "    n_units_l1: 459\n",
      "    dropout_l1: 0.28529844778180163\n",
      "    optimizer: RMSprop\n",
      "    lr: 2.7520615182966584e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Niki/opt/anaconda3/lib/python3.8/site-packages/optuna/structs.py:18: FutureWarning: `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "  warnings.warn(_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "param_search = Param_Search(train_loader, test_loader,\n",
    "            criterion, num_epochs, input_size = input_size, sequence=False,\n",
    "            n_trials=2, study_name='hp_FFNN')\n",
    "\n",
    "param_search.run_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPq8ax182E1R"
   },
   "outputs": [],
   "source": [
    "best_model_FFNN_hp = param_search.save_best_model('FFNN/best_model_FFNN_hp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpe-USry2QQv"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1M3XcKM10qMv"
   },
   "outputs": [],
   "source": [
    "#train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    " #                   hyper_tuning=True, \n",
    "  #                  sequence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4K2tLPT2SU0",
    "outputId": "35687646-db35-491a-e4cb-811cefc2f6f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=540, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (last_layer): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (drop_out1): Dropout(p=0.3, inplace=False)\n",
       "  (drop_out2): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=FFNN(input_size=input_size)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "TBnanKg92jG0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "IqAKKNJu2kAp"
   },
   "outputs": [],
   "source": [
    "best_lr = 3.0174993222703274e-05 ##TRAIN\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a6d85f1038cd41da900f5edc0e80811d",
      "35b5608b0dc44af080ce58a099cd8712",
      "8fb7a0d167284bf79ff068a5aa85e9d2",
      "87899c5edd9342d2ac4b4ccc85ffc239",
      "61e41656f25e4a31b2fa8b673df87c31",
      "dc5de6784a954a5987ec7b2e85238215",
      "1726012577934d22976d0d887c1e9550",
      "1e7aad6fee9c4a78a819560cf7df65d1",
      "f1f8579b4d1b47b08269c9a8fbea17be",
      "f589903ecd1448d6a0eab7fce3b822f2",
      "6172d0db84ac405d90a81ca17e031d5e",
      "0bb7a6aef6f344068b1a1ef798debead",
      "52224afa7ed04cd59f64a33a124f15f8",
      "51871383359e47c5be7e7ed3763f8024",
      "0266ac46c9b9453a9539ea39e6710364",
      "b6812b69f4f840f0b2f733b077e83919",
      "1b704b6614534e2286d7203527c1c216",
      "a68fcc18c0f64e0f9bf6d3002bcab74d",
      "a5f107767969497fb1980cc0ab6262b0",
      "7b802877c3dc4c759de9a0bfc10ff400",
      "131a0ead97934369875db3b372dc2a2a",
      "316a7ea0a7af45a18856c3e17d3f8565",
      "8a4f2ba83b2a4291a5b332d025200abb",
      "2274bbb4d74148b2bf414c324b406965"
     ]
    },
    "id": "YvUj5GJs21OR",
    "outputId": "4edc335c-8663-47dc-a7d6-c135f3808212"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b43288209844b98af0e967f0b70aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e20dc7c3024b3fbb2e3fce3abda43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training model'), FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4599b6d65619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FFNN/ffnn_testing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         sequence=False, verbose=True)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-4032eb2b8cfb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, filename_path, patience, sequence, delta, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# oversample using SMOTE / SMOTEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-261e23ef6093>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2949\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2951\u001b[0;31m             result = self._constructor_sliced(\n\u001b[0m\u001b[1;32m   2952\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mis_object_or_str_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_or_str_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_string_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_excluded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mis_excluded\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mis_excluded_checks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m_is_dtype\u001b[0;34m(arr_or_dtype, condition)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mcondition\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \"\"\"\n\u001b[1;32m    601\u001b[0m     \u001b[0;31m# TODO: gh-15585: consider making the checks stricter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"U\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_excluded_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                        num_epochs, pre_trained=True, filename_path='FFNN/ffnn_testing', patience=3,\n",
    "                        sequence=True, verbose=True)\n",
    "\n",
    "#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q7ojMcD231j"
   },
   "outputs": [],
   "source": [
    "plot_model_scores(F1_train, F1_test, epochs=20,set_ylim=(0.82,0.88))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu4BLdy81hvH"
   },
   "source": [
    "# 2. CONVOLUTIONAL NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9ef0788894af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mround_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mround_repeats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\"\"\"model.py - Model and module class for EfficientNet.\n",
    "   They are built to mirror those in the official TensorFlow implementation.\n",
    "\"\"\"\n",
    "\n",
    "# Author: lukemelas (github username)\n",
    "# Github repo: https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "# With adjustments and added comments by workingcoder (github username).\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from .utils import (\n",
    "    round_filters,\n",
    "    round_repeats,\n",
    "    drop_connect,\n",
    "    get_same_padding_conv2d,\n",
    "    get_model_params,\n",
    "    efficientnet_params,\n",
    "    load_pretrained_weights,\n",
    "    Swish,\n",
    "    MemoryEfficientSwish,\n",
    "    calculate_output_image_size\n",
    ")\n",
    "\n",
    "\n",
    "VALID_MODELS = (\n",
    "    'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3',\n",
    "    'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7',\n",
    "    'efficientnet-b8',\n",
    "\n",
    "    # Support the construction of 'efficientnet-l2' without pretrained weights\n",
    "    'efficientnet-l2'\n",
    ")\n",
    "\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck Block.\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, defined in utils.py.\n",
    "        global_params (namedtuple): GlobalParam, defined in utils.py.\n",
    "        image_size (tuple or list): [image_height, image_width].\n",
    "    References:\n",
    "        [1] https://arxiv.org/abs/1704.04861 (MobileNet v1)\n",
    "        [2] https://arxiv.org/abs/1801.04381 (MobileNet v2)\n",
    "        [3] https://arxiv.org/abs/1905.02244 (MobileNet v3)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params, image_size=None):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum  # pytorch's difference from tensorflow\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n",
    "        self.id_skip = block_args.id_skip  # whether to use skip connection and drop connect\n",
    "\n",
    "        # Expansion phase (Inverted Bottleneck)\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "            # image_size = calculate_output_image_size(image_size, 1) <-- this wouldn't modify image_size\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "        self._depthwise_conv = Conv2d(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "        image_size = calculate_output_image_size(image_size, s)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            Conv2d = get_same_padding_conv2d(image_size=(1, 1))\n",
    "            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n",
    "            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Pointwise convolution phase\n",
    "        final_oup = self._block_args.output_filters\n",
    "        Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"MBConvBlock's forward function.\n",
    "        Args:\n",
    "            inputs (tensor): Input tensor.\n",
    "            drop_connect_rate (bool): Drop connect rate (float, between 0 and 1).\n",
    "        Returns:\n",
    "            Output of this block after processing.\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = self._expand_conv(inputs)\n",
    "            x = self._bn0(x)\n",
    "            x = self._swish(x)\n",
    "\n",
    "        x = self._depthwise_conv(x)\n",
    "        x = self._bn1(x)\n",
    "        x = self._swish(x)\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_reduce(x_squeezed)\n",
    "            x_squeezed = self._swish(x_squeezed)\n",
    "            x_squeezed = self._se_expand(x_squeezed)\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        # Pointwise Convolution\n",
    "        x = self._project_conv(x)\n",
    "        x = self._bn2(x)\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
    "        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
    "            # The combination of skip connection and drop connect brings about stochastic depth.\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "    def set_swish(self, memory_efficient=True):\n",
    "        \"\"\"Sets swish function as memory efficient (for training) or standard (for export).\n",
    "        Args:\n",
    "            memory_efficient (bool): Whether to use memory-efficient version of swish.\n",
    "        \"\"\"\n",
    "        self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
    "\n",
    "        \n",
    "##############\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"EfficientNet model.\n",
    "       Most easily loaded with the .from_name or .from_pretrained methods.\n",
    "    Args:\n",
    "        blocks_args (list[namedtuple]): A list of BlockArgs to construct blocks.\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks.\n",
    "    References:\n",
    "        [1] https://arxiv.org/abs/1905.11946 (EfficientNet)\n",
    "    Example:\n",
    "        >>> import torch\n",
    "        >>> from efficientnet.model import EfficientNet\n",
    "        >>> inputs = torch.rand(1, 3, 224, 224)\n",
    "        >>> model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        >>> model.eval()\n",
    "        >>> outputs = model(inputs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Get stem static or dynamic convolution depending on image size\n",
    "        image_size = global_params.image_size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 1 # one channel -> genomic sequence\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "        image_size = calculate_output_image_size(image_size, 2)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))\n",
    "            image_size = calculate_output_image_size(image_size, block_args.stride)\n",
    "            if block_args.num_repeat > 1:  # modify block_args to keep same output size\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))\n",
    "                # image_size = calculate_output_image_size(image_size, block_args.stride)  # stride = 1\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        if self._global_params.include_top:\n",
    "            self._dropout = nn.Dropout(self._global_params.dropout_rate)\n",
    "            self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "        # set activation to memory efficient swish by default\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "\n",
    "    def set_swish(self, memory_efficient=True):\n",
    "        \"\"\"Sets swish function as memory efficient (for training) or standard (for export).\n",
    "        Args:\n",
    "            memory_efficient (bool): Whether to use memory-efficient version of swish.\n",
    "        \"\"\"\n",
    "        self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
    "        for block in self._blocks:\n",
    "            block.set_swish(memory_efficient)\n",
    "\n",
    "    def extract_endpoints(self, inputs):\n",
    "        \"\"\"Use convolution layer to extract features\n",
    "        from reduction levels i in [1, 2, 3, 4, 5].\n",
    "        Args:\n",
    "            inputs (tensor): Input tensor.\n",
    "        Returns:\n",
    "            Dictionary of last intermediate features\n",
    "            with reduction levels i in [1, 2, 3, 4, 5].\n",
    "            Example:\n",
    "                >>> import torch\n",
    "                >>> from efficientnet.model import EfficientNet\n",
    "                >>> inputs = torch.rand(1, 3, 224, 224)\n",
    "                >>> model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "                >>> endpoints = model.extract_endpoints(inputs)\n",
    "                >>> print(endpoints['reduction_1'].shape)  # torch.Size([1, 16, 112, 112])\n",
    "                >>> print(endpoints['reduction_2'].shape)  # torch.Size([1, 24, 56, 56])\n",
    "                >>> print(endpoints['reduction_3'].shape)  # torch.Size([1, 40, 28, 28])\n",
    "                >>> print(endpoints['reduction_4'].shape)  # torch.Size([1, 112, 14, 14])\n",
    "                >>> print(endpoints['reduction_5'].shape)  # torch.Size([1, 320, 7, 7])\n",
    "                >>> print(endpoints['reduction_6'].shape)  # torch.Size([1, 1280, 7, 7])\n",
    "        \"\"\"\n",
    "        endpoints = dict()\n",
    "\n",
    "        # Stem\n",
    "        x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
    "        prev_x = x\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "            if prev_x.size(2) > x.size(2):\n",
    "                endpoints['reduction_{}'.format(len(endpoints) + 1)] = prev_x\n",
    "            elif idx == len(self._blocks) - 1:\n",
    "                endpoints['reduction_{}'.format(len(endpoints) + 1)] = x\n",
    "            prev_x = x\n",
    "\n",
    "        # Head\n",
    "        x = self._swish(self._bn1(self._conv_head(x)))\n",
    "        endpoints['reduction_{}'.format(len(endpoints) + 1)] = x\n",
    "\n",
    "        return endpoints\n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\"use convolution layer to extract feature .\n",
    "        Args:\n",
    "            inputs (tensor): Input tensor.\n",
    "        Returns:\n",
    "            Output of the final convolution\n",
    "            layer in the efficientnet model.\n",
    "        \"\"\"\n",
    "        # Stem\n",
    "        x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)  # scale drop connect_rate\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = self._swish(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"EfficientNet's forward function.\n",
    "           Calls extract_features to extract features, applies final linear layer, and returns logits.\n",
    "        Args:\n",
    "            inputs (tensor): Input tensor.\n",
    "        Returns:\n",
    "            Output of this model after processing.\n",
    "        \"\"\"\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "        # Pooling and final linear layer\n",
    "        x = self._avg_pooling(x)\n",
    "        if self._global_params.include_top:\n",
    "            x = x.flatten(start_dim=1)\n",
    "            x = self._dropout(x)\n",
    "            x = self._fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_define_model_VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, trial, in_features_INPUT, classes=2):\n",
    "        super(FFNN_define_model, self).__init__()\n",
    "        self.trial = trial\n",
    "        self.in_features_INPUT = in_features_INPUT\n",
    "        self.classes = classes\n",
    "        self.model = []\n",
    "        \n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        layers = []\n",
    "\n",
    "        in_channels = 1\n",
    "        for i in range(n_layers):\n",
    "            out_channels = trial.suggest_categorical(\"out_channels_l{}\".format(i), [16,32, 64, 128, 256, 512])\n",
    "        #   kernel_size = trial.suggest_int(\"kernel_size_l{}\".format(i), 3, 15)\n",
    "            layers.append( nn.Conv1d(in_channels, out_channels, kernel_size=5, stride=1, padding=1) )\n",
    "            layers.append( nn.BatchNorm1d(out_channels) )\n",
    "            layers.append( nn.ReLU() )\n",
    "            layers.append( nn.MaxPool1d(kernel_size=3, stride=1) )\n",
    "\n",
    "            p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "            layers.append(nn.Dropout(p))\n",
    "\n",
    "            in_channels = out_channels\n",
    "\n",
    "        out = out.reshape(out.size(0), -1) \n",
    "        self.last_layer1 = nn.Linear(self.fc_layer_size, 1000) \n",
    "        self.last_layer2 = nn.Linear(1000, self.classes)\n",
    "        layers.append(nn.Linear(in_features, classes))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_define_model(trial, in_features_INPUT, classes=2, self.fc_layer_size):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_channels = 1\n",
    "    for i in range(n_layers):\n",
    "        out_channels = trial.suggest_int(\"out_channels_l{}\".format(i), 16, 128)\n",
    "    #        kernel_size = trial.suggest_int(\"kernel_size_l{}\".format(i), 3, 15)\n",
    "        layers.append( nn.Conv1d(in_channels, out_channels, kernel_size=5, stride=1, padding=1) )\n",
    "        layers.append( nn.BatchNorm1d(out_channels) )\n",
    "        layers.append( nn.ReLU() )\n",
    "        layers.append( nn.MaxPool1d(kernel_size=3, stride=1) )\n",
    "\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_channels = out_channels\n",
    "\n",
    "    out = out.reshape(out.size(0), -1) \n",
    "    self.last_layer1 = nn.Linear(self.fc_layer_size, 1000) \n",
    "    self.last_layer2 = nn.Linear(1000, self.classes)\n",
    "    layers.append(nn.Linear(in_features, classes))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeQBrIDh1qti"
   },
   "outputs": [],
   "source": [
    "def __init__(self, fc_layer_size, classes=2):\n",
    "    super(CNN_multitask, self).__init__()\n",
    "    self.fc_layer_size = fc_layer_size \n",
    "    self.classes = classes\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1), #The average word length in English language is 4.7 characters.\n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1))\n",
    "    \n",
    "    self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1)\n",
    "    \n",
    "        \n",
    "    self.drop_out1 = nn.Dropout(p=0.3)\n",
    "    self.drop_out2 = nn.Dropout(p=0.4)\n",
    "    self.drop_out3 = nn.Dropout(p=0.5)\n",
    "    \n",
    "    self.last_layer1 = nn.Linear(self.fc_layer_size, 1000) \n",
    "    self.last_layer2 = nn.Linear(1000, self.classes)\n",
    "    \n",
    "\n",
    "  def forward(self, x):\n",
    "      \n",
    "      # 2 shared blocks \n",
    "    out = self.layer1(x)\n",
    "    out = self.drop_out1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.drop_out2(out)\n",
    "    out = self.layer3(out) \n",
    "    out = self.drop_out3(out)\n",
    "    \n",
    "    out = out.reshape(out.size(0), -1) \n",
    "    out = self.last_layer1(out)\n",
    "    out = self.last_layer2(out)\n",
    "\n",
    " \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "Requirement already satisfied: torch in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from efficientnet_pytorch) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /Users/Niki/opt/anaconda3/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (1.19.2)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16445 sha256=096e4125e90c900940912447fa9b888cab206e9b03a44ef24a873ffb7b0a33f4\n",
      "  Stored in directory: /Users/Niki/Library/Caches/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = pipe_data_load.return_data(cell_line='H1', \n",
    "                    hyper_tuning=True, \n",
    "                    sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab087b78ebd4bfb9c369b66127b772c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c6cb92d0414c1b9e44cd7720f3739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing model'), FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[192, 1, 257, 5] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0ffd8b036a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_trained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FFNN/ffnn_testing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         sequence=True, verbose=True)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-202667f61e6c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, pre_trained, filename_path, patience, sequence, delta, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;31m# calculate the batch loss as the sum of all the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[192, 1, 257, 5] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "F1_train, F1_test = fit(model, train_loader, test_loader, criterion, optimizer, \n",
    "                        num_epochs, pre_trained=True, filename_path='FFNN/ffnn_testing', patience=3,\n",
    "                        sequence=True, verbose=True)\n",
    "\n",
    "#save_best_model(model, 'FFNN/best_model_FFNN_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzYWmpjmYPIm"
   },
   "source": [
    "# EMBRACENET APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH_kpTB8CtJC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EmbraceNet(nn.Module):\n",
    "  \n",
    "  def __init__(self, device, input_size_list, embracement_size=256, bypass_docking=False):\n",
    "    \"\"\"\n",
    "    Initialize an EmbraceNet module.\n",
    "    Args:\n",
    "      device: A \"torch.device()\" object to allocate internal parameters of the EmbraceNet module.\n",
    "      input_size_list: A list of input sizes.\n",
    "      embracement_size: The length of the output of the embracement layer (\"c\" in the paper).\n",
    "      bypass_docking: Bypass docking step, i.e., connect the input data directly to the embracement layer. If True, input_data must have a shape of [batch_size, embracement_size].\n",
    "    \"\"\"\n",
    "    super(EmbraceNet, self).__init__()\n",
    "\n",
    "    self.device = device\n",
    "    self.input_size_list = input_size_list\n",
    "    self.embracement_size = embracement_size\n",
    "    self.bypass_docking = bypass_docking\n",
    "\n",
    "    if (not bypass_docking):\n",
    "      for i, input_size in enumerate(input_size_list):\n",
    "        setattr(self, 'docking_%d' % (i), nn.Linear(input_size, embracement_size))\n",
    "\n",
    "\n",
    "  def forward(self, input_list, availabilities=None, selection_probabilities=None):\n",
    "    \"\"\"\n",
    "    Forward input data to the EmbraceNet module.\n",
    "    Args:\n",
    "      input_list: A list of input data. Each input data should have a size as in input_size_list.\n",
    "      availabilities: A 2-D tensor of shape [batch_size, num_modalities], which represents the availability of data for each modality. If None, it assumes that data of all modalities are available.\n",
    "      selection_probabilities: A 2-D tensor of shape [batch_size, num_modalities], which represents probabilities that output of each docking layer will be selected (\"p\" in the paper). If None, the same probability of being selected will be used for each docking layer.\n",
    "    Returns:\n",
    "      A 2-D tensor of shape [batch_size, embracement_size] that is the embraced output.\n",
    "    \"\"\"\n",
    "\n",
    "    # check input data\n",
    "    assert len(input_list) == len(self.input_size_list)\n",
    "    num_modalities = len(input_list)\n",
    "    batch_size = input_list[0].shape[0]\n",
    "    \n",
    "\n",
    "    # docking layer\n",
    "    docking_output_list = []\n",
    "    if (self.bypass_docking):\n",
    "      docking_output_list = input_list\n",
    "    else:\n",
    "      for i, input_data in enumerate(input_list):\n",
    "        x = getattr(self, 'docking_%d' % (i))(input_data)\n",
    "        x = nn.functional.relu(x)\n",
    "        docking_output_list.append(x)\n",
    "    \n",
    "\n",
    "    # check availabilities\n",
    "    if (availabilities is None):\n",
    "      availabilities = torch.ones(batch_size, len(input_list), dtype=torch.float, device=self.device)\n",
    "    else:\n",
    "      availabilities = availabilities.float()\n",
    "    \n",
    "\n",
    "    # adjust selection probabilities\n",
    "    if (selection_probabilities is None):\n",
    "      selection_probabilities = torch.ones(batch_size, len(input_list), dtype=torch.float, device=self.device)\n",
    "    selection_probabilities = torch.mul(selection_probabilities, availabilities)\n",
    "\n",
    "    probability_sum = torch.sum(selection_probabilities, dim=-1, keepdim=True)\n",
    "    selection_probabilities = torch.div(selection_probabilities, probability_sum)\n",
    "\n",
    "\n",
    "    # stack docking outputs\n",
    "    docking_output_stack = torch.stack(docking_output_list, dim=-1)  # [batch_size, embracement_size, num_modalities]\n",
    "\n",
    "\n",
    "    # embrace\n",
    "    modality_indices = torch.multinomial(selection_probabilities, num_samples=self.embracement_size, replacement=True)  # [batch_size, embracement_size]\n",
    "    modality_toggles = nn.functional.one_hot(modality_indices, num_classes=num_modalities).float()  # [batch_size, embracement_size, num_modalities]\n",
    "\n",
    "    embracement_output_stack = torch.mul(docking_output_stack, modality_toggles)\n",
    "    embracement_output = torch.sum(embracement_output_stack, dim=-1)  # [batch_size, embracement_size]\n",
    "\n",
    "    return embracement_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goeL7ZZU--j-"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class VGG_pre(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_pre, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.ReLU(),\n",
    "      #      nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2),\n",
    "       #     nn.BatchNorm2d(32),\n",
    "        #    nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "     #       nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
    "      #      nn.BatchNorm2d(64),\n",
    "       #     nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.drop_out1 = nn.Dropout(p=0.3)\n",
    "        self.drop_out2 = nn.Dropout(p=0.4)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.drop_out1(out)\n",
    "      out = self.layer2(out)\n",
    "      out = self.drop_out2(out)\n",
    "      out = out.reshape(out.size(0), -1) \n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEBTsRqCbZLh"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "training_loader = defaultdict(lambda:0)\n",
    "validation_loader = defaultdict(lambda:0)\n",
    "\n",
    "training_loader['left'] = loader_imag_train_L\n",
    "training_loader['central'] = loader_imag_train_C\n",
    "training_loader['right'] = loader_imag_train_R\n",
    "\n",
    "validation_loader['left'] = loader_imag_validation_L\n",
    "validation_loader['central'] = loader_imag_validation_C\n",
    "validation_loader['right'] = loader_imag_validation_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cenBsd-Xyxhy",
    "outputId": "2fbc2005-7fcb-4ca3-ea14-96b9a571cace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'central': <torch.utils.data.dataloader.DataLoader at 0x7f0810cb6e10>,\n",
       "             'left': <torch.utils.data.dataloader.DataLoader at 0x7f07ffb169d0>,\n",
       "             'right': <torch.utils.data.dataloader.DataLoader at 0x7f07ffb92250>})"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF9zMxSKYN1n"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class EmbraceNetMultimodal(nn.Module):\n",
    "  def __init__(self, device, n_classes, hyperparameters_tuning=False, args=None):\n",
    "    super(EmbraceNetMultimodal, self).__init__()\n",
    "    \n",
    "    \n",
    "    # input parameters\n",
    "    self.device = device\n",
    "    self.n_classes = n_classes\n",
    "    self.args = args\n",
    "    self.hyperparameters_tuning = hyperparameters_tuning\n",
    "\n",
    "    \n",
    "    # VGG convolutional neural network\n",
    "    self.VGG_left = VGG_pre()\n",
    "    self.VGG_central = VGG_pre()\n",
    "    self.VGG_right = VGG_pre()\n",
    "\n",
    "    # load previously trained models to find optimal hyperparameters\n",
    "    if self.hyperparameters_tuning:\n",
    "      load_model(self.VGG_left, 'best_model_L_hp.pt')\n",
    "      load_model(self.VGG_central, 'best_model_C_hp.pt')\n",
    "      load_model(self.VGG_right, 'best_model_R_hp.pt')\n",
    "    \n",
    "    # load previously trained models for final testing\n",
    "    else:\n",
    "      load_model(self.VGG_left, 'best_model_L_test.pt')\n",
    "      load_model(self.VGG_central, 'best_model_C_test.pt')\n",
    "      load_model(self.VGG_right, 'best_model_R_test.pt')\n",
    "\n",
    "    # freeze layers\n",
    "    for param in self.VGG_left.parameters():\n",
    "      param.requires_grad = False\n",
    "    for param in self.VGG_central.parameters():\n",
    "      param.requires_grad = False\n",
    "    for param in self.VGG_right.parameters():\n",
    "      param.requires_grad = False\n",
    "        \n",
    "    self.pre_output_size = (5*64*16) #5120\n",
    "\n",
    "    # embracenet\n",
    "    self.embracenet = EmbraceNet(device=self.device, \n",
    "                                 input_size_list=[self.pre_output_size, self.pre_output_size, self.pre_output_size], \n",
    "                                 embracement_size=512)\n",
    "\n",
    "    # post embracement layers\n",
    "    self.post = nn.Linear(in_features=512, out_features=self.n_classes)\n",
    "\n",
    "  \n",
    "  def forward(self, x, availabilities=None, selection_probabilities=None):\n",
    "\n",
    "    x_left, x_central, x_right = x\n",
    "\n",
    "    x_left_final = self.VGG_left(x_left)\n",
    "    x_central_final = self.VGG_central(x_central)\n",
    "    x_right_final = self.VGG_right(x_right)\n",
    "\n",
    "    # drop left or right modality\n",
    "   # availabilities = None\n",
    "    #if (self.args.model_drop_left or self.args.model_drop_central or self.args.model_drop_right):\n",
    "   #   availabilities = torch.ones([x.shape[0], 3], device=self.device)\n",
    "    #  if (self.args.model_drop_left):\n",
    "     #   availabilities[:, 0] = 0\n",
    "   #   if (self.args.model_drop_central):\n",
    "    #    availabilities[:, 1] = 0\n",
    "     # if (self.args.model_drop_right):\n",
    "      #  availabilities[:, 2] = 0\n",
    "\n",
    "    # dropout during training\n",
    " #   if (self.is_training and self.args.model_dropout):\n",
    "  #    dropout_prob = torch.rand(1, device=self.device)[0]\n",
    "   #   if (dropout_prob >= 0.5):\n",
    "    #    target_modalities = torch.round(torch.rand([x.shape[0]], device=self.device)).to(torch.int64)\n",
    "     #  availabilities = nn.functional.one_hot(target_modalities, num_classes=2).float()\n",
    "\n",
    "    # embrace\n",
    "    embracenet = self.embracenet([x_left_final, x_central_final, x_right_final]) #, availabilities=availabilities)\n",
    "\n",
    "    # employ final layers\n",
    "    output = self.post(embracenet)\n",
    "\n",
    "    # output softmax\n",
    "    return output\n",
    "    \n",
    "   # return nn.functional.log_softmax(output, dim=-1) #not needed since it's already applied\n",
    "   #by cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6Szz7dYTiYZ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 50\n",
    "num_classes = 5\n",
    "#learning_rate=0.0001\n",
    "#optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "#optimizer = torch.optim.Adam([x_left, x_central, x_right],lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atm7JYZTRRWH"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.nn as nn\n",
    "#import thop\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "class Param_Search_Multimodal():\n",
    "\n",
    "  \"\"\"Performs the hyper parameters tuning by using a TPE (Tree-structured Parzen Estimator) \n",
    "    algorithm sampler.  \n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): neural network model.\n",
    "    train_loader (DataLoader): dictionary of training DataLoader objects. Keys of the\n",
    "        dictionary must be 'FFNN', 'CNN', 'D2V_CNN'.\n",
    "    test_loader (DataLoader): dictionary of testing DataLoader objects. Keys of the\n",
    "        dictionary must be 'FFNN', 'CNN', 'D2V_CNN'.\n",
    "    criterion : loss function for training the model.\n",
    "    num_epochs (int): number of epochs.\n",
    "    study_name (str): name of the Optuna study object.\n",
    "    n_trial (int): number of trials to perform in the Optuna study.\n",
    "        Default: 4\n",
    "    \n",
    "    Attributes:\n",
    "    ------------------\n",
    "    best_model: stores the weights of the common layers of the best performing model.\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "  Prints values of the optimised hyperparameters and saves the parameters of the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "  def __init__(self, \n",
    "               model, \n",
    "               train_loader, \n",
    "               test_loader,\n",
    "               criterion,\n",
    "               num_epochs,\n",
    "               n_trials,\n",
    "               study_name):\n",
    "    self.model = model\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.criterion = criterion\n",
    "    self.num_epochs = num_epochs\n",
    "    self.n_trials = n_trials\n",
    "    self.study_name = study_name\n",
    "    self.len_train_loader = len(train_loader['FFNN'])\n",
    "    self.len_test_loader = len(test_loader['FFNN'])\n",
    "    self.best_model = None\n",
    "\n",
    "  def objective(self, trial):\n",
    "    \"\"\"Defines the objective to be optimised (F1 test score) and saves\n",
    "    each final model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate the model\n",
    "    model = self.model\n",
    "\n",
    "    # generate the possible optimizers\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    # convert model data type to double\n",
    "    model = model.double()\n",
    "    \n",
    "    # Define the training and testing phases\n",
    "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "      train_loss = 0.0\n",
    "      test_loss = 0.0\n",
    "      f1_test = 0.0\n",
    "    \n",
    "      # set the model in training modality\n",
    "      model.train()\n",
    "      for load1, load2 in tqdm(zip(self.train_loader['FFNN'],\n",
    "                                          self.train_loader['CNN'])) \n",
    "                                      desc='Training model', total = self.len_train_loader):\n",
    "        x_1, target = load1\n",
    "        x_2, _ = load2\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model([x_1.double(), x_2.double()])\n",
    "        # calculate the batch loss as a sum of the single losses\n",
    "        loss = self.criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss wrt model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()      \n",
    "        \n",
    "        \n",
    "      # set the model in testing modality\n",
    "      model.eval()\n",
    "      for load1, load2 in tqdm(zip(self.test_loader['FFNN'],\n",
    "                                          self.test_loader['CNN']), \n",
    "                                      desc='Testing model', total = self.len_test_loader):\n",
    "        x_1, target = load1\n",
    "        x_2, _, = load2\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output1, output2 = model([x_1.double(), x_2.double()])\n",
    "        # calculate the batch loss as a sum of the single losses\n",
    "        loss = self.criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item() \n",
    "        # calculate F1 test score as weighted sum of the single F1 scores\n",
    "        f1_test += F1(output,target) \n",
    "        \n",
    "      # calculate epoch score by dividing by the number of observations\n",
    "      f1_test /= self.len_test_loader\n",
    "      # pass the score of the epoch to the study to monitor the intermediate objective values    \n",
    "      trial.report(f1_test, epoch)\n",
    "\n",
    "    # save the final model named with the number of the trial \n",
    "    with open(\"{}{}.pickle\".format(self.study_name,trial.number), \"wb\") as fout:\n",
    "      pickle.dump(model, fout)\n",
    "    \n",
    "    # return F1 score to the study        \n",
    "    return f1_test\n",
    "\n",
    "\n",
    "\n",
    "  def run_trial(self):\n",
    "    \"\"\"Runs Optuna study and stores the best model in class attribute 'best_model'.\"\"\"\n",
    "\n",
    "    # create a new study or load a pre-existing study. use sqlite backend to store the study.\n",
    "    study = optuna.create_study(study_name=self.study_name, direction=\"maximize\", \n",
    "                                storage='sqlite:///SA_optuna_tuning.db', load_if_exists=True)\n",
    "\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "    \n",
    "    # if the number of already completed trials is lower than the total number of trials passed as\n",
    "    #argument, perform the remaining trials \n",
    "    if len(complete_trials)<self.n_trials:\n",
    "        # set the number of trials to be performed equal to the number of missing trials\n",
    "        self.n_trials -= len(complete_trials)\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "        complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "        \n",
    "    # store the best model found in the class\n",
    "    with open(\"{}{}.pickle\".format(self.study_name, study.best_trial.number), \"rb\") as fin:\n",
    "        best_model = pickle.load(fin)\n",
    "\n",
    "    self.best_model = best_model\n",
    "    \n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "      print(\"    {}: {}\".format(key, value))\n",
    "                                          \n",
    "\n",
    "    with open(\"{}.pickle\".format(study.best_trial.number), \"rb\") as fin:\n",
    "      best_model = pickle.load(fin)\n",
    "    \n",
    "    # store only best model\n",
    "    self.best_model = best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwpyKxqQexj1"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def fit_multimodal(model, \n",
    "                   train_loader, \n",
    "                   test_loader, \n",
    "                   criterion, \n",
    "                   optimizer, \n",
    "                   num_epochs, \n",
    "                   filename_path, \n",
    "                   verbose=True): \n",
    "  \"\"\"Performs the training of the multitask model. It implements also early stopping\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    model (torch.nn.Module): neural network model.\n",
    "    train_loader (DataLoader): dictioary of training DataLoader objects. Keys of the\n",
    "        dictionary must be 'FFNN', 'CNN', 'D2V_CNN'.\n",
    "    test_loader (DataLoader): dictionary of testing DataLoader objects. Keys of the\n",
    "        dictionary must be 'FFNN', 'CNN', 'D2V_CNN'.\n",
    "    criterion: loss function for training the model.\n",
    "    optimizer (torch.optim): optimization algorithm for training the model. \n",
    "    num_epochs (int): number of epochs.\n",
    "    filename_path (str): where the weights of the model at each epoch will be stored. \n",
    "        Indicate only the name of the folder.\n",
    "    patience (int): number of epochs in which the test error is not anymore decreasing\n",
    "        before stopping the training.\n",
    "    delta (int): minimum decrease in the test error to continue with the training.\n",
    "        Default:0\n",
    "    verbose (bool): prints the training error, test error, F1 training score, F1 test score \n",
    "        at each epoch.\n",
    "        Default: True\n",
    "    \n",
    "    Attributes:\n",
    "    ------------------\n",
    "    f1_train_scores: stores the F1 training scores for each epoch.\n",
    "    f1_test_scores: stores the F1 test scores for each epoch.\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "    Lists of F1 training scores and F1 test scores at each epoch.\n",
    "    Prints training error, test error, F1 training score, F1 test score at each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "  basepath = 'exp'\n",
    "\n",
    "  # keep track of epoch losses \n",
    "  f1_train_scores = []\n",
    "  f1_test_scores = []\n",
    "\n",
    "  # convert model data type to double\n",
    "  model = model.double()\n",
    "\n",
    "  # define early stopping\n",
    "  early_stopping = EarlyStopping(patience=patience, delta=delta, verbose=True)\n",
    "\n",
    "  len_train_loader = len(train_loader['FFNN'])\n",
    "  len_test_loader = len(test_loader['FFNN'])\n",
    "    \n",
    "\n",
    "  for epoch in tqdm(range(1, num_epochs + 1), desc='Epochs'):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    f1_train = 0.0\n",
    "    f1_test = 0.0\n",
    "    \n",
    "    # if there is already a trained model stored for a specific epoch, load the model\n",
    "    #and don't retrain the model\n",
    "    PATH = os.path.join(basepath, filename_path + '_' + str(epoch) + '.pt')\n",
    "    if os.path.exists(PATH):\n",
    "      checkpoint = torch.load(PATH)\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      f1_train = checkpoint['F1_train']\n",
    "      f1_test = checkpoint['F1_test']\n",
    "      train_loss = checkpoint['train_loss']\n",
    "      test_loss = checkpoint['test_loss']\n",
    "        \n",
    "    else:\n",
    "      # set the model in training modality\n",
    "      model.train()\n",
    "      for load1, load2, load3 in tqdm(zip(train_loader['FFNN'],\n",
    "                                          train_loader['CNN']), \n",
    "                                      desc='Testing model', total = len_train_loader):\n",
    "        x_1, target = load1\n",
    "        x_2, _ = load2\n",
    "        x_3, _ = load3\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model([x_1.double(), x_2.double()])\n",
    "        # calculate the batch loss as the sum of all the losses\n",
    "        loss = criterion(output1 target) \n",
    "        # backward pass: compute gradient of the loss wrt model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()\n",
    "        # calculate F1 training score as a weighted sum of the single F1 scores\n",
    "        f1_train +=  F1(output,target) \n",
    "        \n",
    "        \n",
    "      # set the model in testing modality\n",
    "      model.eval()\n",
    "      for load1, load2, load3 in tqdm(zip(test_loader['FFNN'],\n",
    "                                          test_loader['CNN']), \n",
    "                                      desc='Testing model', total = len_test_loader):\n",
    "        x_1, target = load1\n",
    "        x_2, _ = load2\n",
    "        x_3, _ = load3\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model([x_1.double(), x_2.double()])\n",
    "        # calculate the batch loss as the sum of all the losses\n",
    "        loss = criterion(output, target) \n",
    "        # update test loss\n",
    "        test_loss += loss.item()\n",
    "        # calculate F1 test score as a weighted sum of the single F1 scores\n",
    "        f1_test +=  F1(output,target) \n",
    "        \n",
    "        \n",
    "    # save the model weights, epoch, scores and losses at each epoch\n",
    "    model_param = model.state_dict()\n",
    "    PATH = os.path.join(basepath, filename_path + '_' + str(epoch) + '.pt')\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model_param,\n",
    "                'F1_train': f1_train,\n",
    "                'F1_test': f1_test,\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': test_loss},\n",
    "               PATH)\n",
    "     \n",
    "    \n",
    "    # calculate epoch score by dividing by the number of observations\n",
    "    f1_train /= len_train_loader\n",
    "    f1_test /= len_test_loader\n",
    "    # store epoch scores\n",
    "    f1_train_scores.append(f1_train)    \n",
    "    f1_test_scores.append(f1_test)\n",
    "      \n",
    "    # print training/test statistics \n",
    "    if verbose == True:\n",
    "      print('Epoch: {} \\tTraining F1 score: {:.4f} \\tTest F1 score: {:.4f} \\tTraining Loss: {:.4f} \\tTest Loss: {:.4f}'.format(\n",
    "      epoch, f1_train, f1_test, train_loss, test_loss))\n",
    "      \n",
    "    # early stop the model if the test loss is not improving\n",
    "    early_stopping(test_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "      print('Early stopping the training')\n",
    "      # reload the previous best model before the test loss started decreasing\n",
    "      best_checkpoint = torch.load(os.path.join(basepath,filename_path + '_' + '{}'.format(epoch-patience) + '.pt'))\n",
    "      model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "      break\n",
    "    \n",
    "        \n",
    "  # return the scores at each epoch\n",
    "  return f1_train_scores, f1_test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtReJYQW7bBj"
   },
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDe4BnP_7eEw"
   },
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_Thesis_BIOINF_multimodal_NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0266ac46c9b9453a9539ea39e6710364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bb7a6aef6f344068b1a1ef798debead": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6812b69f4f840f0b2f733b077e83919",
      "placeholder": "​",
      "style": "IPY_MODEL_0266ac46c9b9453a9539ea39e6710364",
      "value": " 405/? [01:19&lt;00:00,  5.12it/s]"
     }
    },
    "131a0ead97934369875db3b372dc2a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1726012577934d22976d0d887c1e9550": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b704b6614534e2286d7203527c1c216": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5f107767969497fb1980cc0ab6262b0",
       "IPY_MODEL_7b802877c3dc4c759de9a0bfc10ff400"
      ],
      "layout": "IPY_MODEL_a68fcc18c0f64e0f9bf6d3002bcab74d"
     }
    },
    "1e7aad6fee9c4a78a819560cf7df65d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2274bbb4d74148b2bf414c324b406965": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a7ea0a7af45a18856c3e17d3f8565": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b5608b0dc44af080ce58a099cd8712": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51871383359e47c5be7e7ed3763f8024": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52224afa7ed04cd59f64a33a124f15f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6172d0db84ac405d90a81ca17e031d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Training model: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51871383359e47c5be7e7ed3763f8024",
      "max": 404,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52224afa7ed04cd59f64a33a124f15f8",
      "value": 404
     }
    },
    "61e41656f25e4a31b2fa8b673df87c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b802877c3dc4c759de9a0bfc10ff400": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2274bbb4d74148b2bf414c324b406965",
      "placeholder": "​",
      "style": "IPY_MODEL_8a4f2ba83b2a4291a5b332d025200abb",
      "value": " 37/? [14:25&lt;00:00, 23.40s/it]"
     }
    },
    "87899c5edd9342d2ac4b4ccc85ffc239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e7aad6fee9c4a78a819560cf7df65d1",
      "placeholder": "​",
      "style": "IPY_MODEL_1726012577934d22976d0d887c1e9550",
      "value": " 0/2 [01:32&lt;?, ?it/s]"
     }
    },
    "8a4f2ba83b2a4291a5b332d025200abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fb7a0d167284bf79ff068a5aa85e9d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Epochs:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc5de6784a954a5987ec7b2e85238215",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61e41656f25e4a31b2fa8b673df87c31",
      "value": 0
     }
    },
    "a5f107767969497fb1980cc0ab6262b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Testing model: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_316a7ea0a7af45a18856c3e17d3f8565",
      "max": 36,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_131a0ead97934369875db3b372dc2a2a",
      "value": 36
     }
    },
    "a68fcc18c0f64e0f9bf6d3002bcab74d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d85f1038cd41da900f5edc0e80811d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fb7a0d167284bf79ff068a5aa85e9d2",
       "IPY_MODEL_87899c5edd9342d2ac4b4ccc85ffc239"
      ],
      "layout": "IPY_MODEL_35b5608b0dc44af080ce58a099cd8712"
     }
    },
    "b6812b69f4f840f0b2f733b077e83919": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc5de6784a954a5987ec7b2e85238215": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f8579b4d1b47b08269c9a8fbea17be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6172d0db84ac405d90a81ca17e031d5e",
       "IPY_MODEL_0bb7a6aef6f344068b1a1ef798debead"
      ],
      "layout": "IPY_MODEL_f589903ecd1448d6a0eab7fce3b822f2"
     }
    },
    "f589903ecd1448d6a0eab7fce3b822f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
