{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d73c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pickle\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from BIOINF_tesi.data_pipe import CELL_LINES, TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad76158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad69a690b8a4feda9c356aaf1487907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter tasks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c06c72f76e4f31abaf18564b55bb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter cell lines:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebd347952cf4e52bb5ee8072974e5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004d39ebfa8a4aaeb506a8c9998d1838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7a3a50f57a4b0fba8e063073508c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf57a74953b4a9fb86c21fd16e95f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6cdb8c930e42769d331a42c2b71132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d067c1cac44695a35f72e807be7fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbecb83971824b148b555614658f7684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109858ec9f0d41aeb54b12a552cc33c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5d983786ac4a1f9bae07709640c279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f6d53502d44315856fef29b1667ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1d70b693fa438f851a8f4d8410c7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce22c2575bc42d684b7640a7934ed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff86896874f49b28a8b50e8cd409a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7976025ee90456b83fa4404b555a857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea99af04029b4a4b8aadb5b1a25feb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c38407abf44ecaa006cb221884964c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcf8f921b4548c2a6e313d4eeb57638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5445847d5b2848dfbbe464bcaa9beb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ce665365f54355a829435f450cdbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2a4872556f4ef8865b8133c3b7a6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4769392bbd46baa1cd39618ff69f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed1bfd82e264a459c6efe9785460941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EmbraceNetMultimodal_NoTrain:\n\tMissing key(s) in state_dict: \"FFNN.model.3.weight\", \"FFNN.model.3.bias\", \"CNN.CNN_model.10.weight\", \"CNN.CNN_model.10.bias\", \"CNN.CNN_model.11.weight\", \"CNN.CNN_model.11.bias\", \"CNN.CNN_model.11.running_mean\", \"CNN.CNN_model.11.running_var\", \"CNN.CNN_model.15.weight\", \"CNN.CNN_model.15.bias\", \"CNN.CNN_model.16.weight\", \"CNN.CNN_model.16.bias\", \"CNN.CNN_model.16.running_mean\", \"CNN.CNN_model.16.running_var\". \n\tUnexpected key(s) in state_dict: \"post.3.weight\", \"post.3.bias\". \n\tsize mismatch for CNN.CNN_model.0.weight: copying a param with shape torch.Size([32, 4, 5]) from checkpoint, the shape in current model is torch.Size([16, 4, 11]).\n\tsize mismatch for CNN.CNN_model.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.5.weight: copying a param with shape torch.Size([96, 32, 15]) from checkpoint, the shape in current model is torch.Size([64, 16, 11]).\n\tsize mismatch for CNN.CNN_model.5.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for embracenet.docking_0.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([768, 128]).\n\tsize mismatch for embracenet.docking_0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for embracenet.docking_1.weight: copying a param with shape torch.Size([1024, 5568]) from checkpoint, the shape in current model is torch.Size([768, 1024]).\n\tsize mismatch for embracenet.docking_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for post.0.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for post.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-860671db0dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBIOINF_tesi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompare_Models_Result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompare_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompare_Models_Result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Prediction-of-Active-and-Inactive-Regulatory-Regions-with-Embracenet-Multimodal-Neural-Network-/BIOINF_tesi/visual/visual.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, device, base_model, comparison_models, augmentation_base_model, n_folds, cell_lines, tasks, pval_dict)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mb_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iter models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                             \u001b[0mbase_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mc_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Prediction-of-Active-and-Inactive-Regulatory-Regions-with-Embracenet-Multimodal-Neural-Network-/BIOINF_tesi/visual/visual.py\u001b[0m in \u001b[0;36mget_model_predictions\u001b[0;34m(self, cell_line, task, model, n_iteration, device)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{cell_line}_{model}_{task}_{n_iteration}_test_.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EmbraceNetMultimodal_NoTrain:\n\tMissing key(s) in state_dict: \"FFNN.model.3.weight\", \"FFNN.model.3.bias\", \"CNN.CNN_model.10.weight\", \"CNN.CNN_model.10.bias\", \"CNN.CNN_model.11.weight\", \"CNN.CNN_model.11.bias\", \"CNN.CNN_model.11.running_mean\", \"CNN.CNN_model.11.running_var\", \"CNN.CNN_model.15.weight\", \"CNN.CNN_model.15.bias\", \"CNN.CNN_model.16.weight\", \"CNN.CNN_model.16.bias\", \"CNN.CNN_model.16.running_mean\", \"CNN.CNN_model.16.running_var\". \n\tUnexpected key(s) in state_dict: \"post.3.weight\", \"post.3.bias\". \n\tsize mismatch for CNN.CNN_model.0.weight: copying a param with shape torch.Size([32, 4, 5]) from checkpoint, the shape in current model is torch.Size([16, 4, 11]).\n\tsize mismatch for CNN.CNN_model.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for CNN.CNN_model.5.weight: copying a param with shape torch.Size([96, 32, 15]) from checkpoint, the shape in current model is torch.Size([64, 16, 11]).\n\tsize mismatch for CNN.CNN_model.5.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for CNN.CNN_model.6.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for embracenet.docking_0.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([768, 128]).\n\tsize mismatch for embracenet.docking_0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for embracenet.docking_1.weight: copying a param with shape torch.Size([1024, 5568]) from checkpoint, the shape in current model is torch.Size([768, 1024]).\n\tsize mismatch for embracenet.docking_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for post.0.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for post.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "from BIOINF_tesi.visual import Compare_Models_Result\n",
    "compare_models = Compare_Models_Result()\n",
    "compare_models(device, tasks=TASKS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bce948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd42f20cc5464a72bbc26a214ab32b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter tasks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7f4092238546e59fef2d760bebde1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter cell lines:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7bd48bf6b54326867d0d56ed4b6c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104134083e394b7e97eba2e1d6dfa15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56f4f99678d4c0ebca2c44cea58640c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003f95a874e04bd8b01bc277abb2a2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9760f12a69442ab82850937614379ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9d0367f56e42f19ab300dd326c5734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5ef34a4614a8486116117ad5580c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a40fe66d8345719dda2bb3e2c376fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739a4e4892774d73a2e81750529e99e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter folds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688a83dd5d5c4a039056543a8b24eac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6f6dc7cce44bf99fe8c29db6c14b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3080fb8a7962454fb6145deb42a87921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iter models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'active_P_vs_inactive_P'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d25c5d7b038f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBIOINF_tesi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompare_Models_Result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompare_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompare_Models_Result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCELL_LINES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Prediction-of-Active-and-Inactive-Regulatory-Regions-with-Embracenet-Multimodal-Neural-Network-/BIOINF_tesi/visual/visual.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, device, base_model, comparison_models, augmentation_base_model, n_folds, cell_lines, tasks, pval_dict)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mpipe_data_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuild_DataLoader_Pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{task}.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mdata_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_data_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcell_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Iter cell lines'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Prediction-of-Active-and-Inactive-Regulatory-Regions-with-Embracenet-Multimodal-Neural-Network-/BIOINF_tesi/visual/visual.py\u001b[0m in \u001b[0;36mget_model_difference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'active_P_vs_inactive_P'"
     ]
    }
   ],
   "source": [
    "from BIOINF_tesi.visual import Compare_Models_Result\n",
    "compare_models = Compare_Models_Result()\n",
    "compare_models(device, tasks=TASKS[1], cell_lines=CELL_LINES[4:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
